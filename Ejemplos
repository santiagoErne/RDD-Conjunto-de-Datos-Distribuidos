from pyspark.context import SparkContext
from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
# Inicializar SparkContext
ejemplo = SparkContext.getOrCreate()

#map
rdd = ejemplo.parallelize(["b", "a", "c"])
sorted(rdd.map(lambda x: (x, 1)).collect())

[('a', 1), ('b', 1), ('c', 1)]

#filter
rdd = ejemplo.parallelize([1, 2, 3, 4, 5])
rdd.filter(lambda x: x % 2 == 0).collect()

[2, 4]

#flatMap
rdd = ejemplo.parallelize([2, 3, 4])
sorted(rdd.flatMap(lambda x: range(1, x)).collect())
[1, 1, 1, 2, 2, 3]
sorted(rdd.flatMap(lambda x: [(x, x), (x, x)]).collect())

[(2, 2), (2, 2), (3, 3), (3, 3), (4, 4), (4, 4)]

#union
rdd = ejemplo.parallelize([1, 1, 2, 3])
rdd.union(rdd).collect()

[1, 1, 2, 3, 1, 1, 2, 3]
